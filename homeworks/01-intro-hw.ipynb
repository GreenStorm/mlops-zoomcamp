{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/python/3.10.13/lib/python3.10/site-packages (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/codespace/.local/lib/python3.10/site-packages (from pyarrow) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_202301 = pd.read_parquet('../data/yellow_tripdata_2023-01.parquet')\n",
    "df_202302 = pd.read_parquet('../data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Downloading the data\n",
    "For January 2023, how many columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_1 = len(df_202301.head().columns)\n",
    "display(answer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         14.30                   2.5         0.00  \n",
       "1                    1.0         16.90                   2.5         0.00  \n",
       "2                    1.0         34.90                   2.5         0.00  \n",
       "3                    1.0         20.85                   0.0         1.25  \n",
       "4                    1.0         19.68                   2.5         0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_202301.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.59435124195458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_duration_column_by_minutes(df):\n",
    "    df[\"duration\"] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df[\"duration\"] = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    return df\n",
    "\n",
    "df_202301_with_duration = add_duration_column_by_minutes(df_202301)\n",
    "answer_2 =df_202301_with_duration.duration.std()\n",
    "display(answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q3. Dropping outliers\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_duration(df):\n",
    "    return df.duration.describe().apply(lambda x: format(x, 'f'))\n",
    "\n",
    "def drop_outliers(df):\n",
    "    # drop less than 1 min and  greater than 60 min\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3066766.000000\n",
       "mean          15.668995\n",
       "std           42.594351\n",
       "min          -29.200000\n",
       "25%            7.116667\n",
       "50%           11.516667\n",
       "75%           18.300000\n",
       "max        10029.183333\n",
       "Name: duration, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    3009173.000000\n",
       "mean          14.204864\n",
       "std            9.939386\n",
       "min            1.000000\n",
       "25%            7.216667\n",
       "50%           11.550000\n",
       "75%           18.183333\n",
       "max           60.000000\n",
       "Name: duration, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "duration\n",
       "7.000000     3697\n",
       "8.000000     3665\n",
       "9.000000     3558\n",
       "6.000000     3523\n",
       "11.000000    3518\n",
       "             ... \n",
       "59.916667      27\n",
       "59.483333      26\n",
       "59.333333      26\n",
       "58.233333      26\n",
       "59.783333      23\n",
       "Name: count, Length: 3541, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observe outlier dropping and explore\n",
    "display(describe_duration(df_202301))\n",
    "df_202301_no_outliers = drop_outliers(df_202301_with_duration)\n",
    "display(describe_duration(df_202301_no_outliers))\n",
    "display(df_202301_no_outliers[\"duration\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812202822125979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_3 = df_202301_no_outliers.duration.count()/df_202301.duration.count()\n",
    "display (answer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    numerical = ['trip_distance']\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    \n",
    "    return train_dicts\n",
    "    \n",
    "def train(train_dicts):\n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6537/3891565401.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_df = one_hot_encode(df_202301_no_outliers)\n",
    "train_encoded_df = train(encoded_df)\n",
    "answer_4 = train_encoded_df.get_shape()[1]\n",
    "display(answer_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64\n",
    "* 11.64\n",
    "* 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(df):\n",
    "  \n",
    "    df = add_duration_column_by_minutes(df)\n",
    "    df = drop_outliers(df)\n",
    "    train_dicts = one_hot_encode(df)\n",
    "    X_train =  train(train_dicts)\n",
    "\n",
    "    target = 'duration'\n",
    "    y_train = df[target].values\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_train)\n",
    "\n",
    "    rmse = mean_squared_error(y_train, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6537/3891565401.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.656752078217351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_5 = train_and_predict(df_202301)\n",
    "display(answer_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(df_train, df_valid):\n",
    "    df_train = add_duration_column_by_minutes(df_train)\n",
    "    train_dicts = drop_outliers(df_train)\n",
    "    X_train =  train(train_dicts)\n",
    "    target = 'duration'\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    df_valid = add_duration_column_by_minutes(df_valid)\n",
    "    df_valid = drop_outliers(df_valid)\n",
    "    valid_dicts = one_hot_encode(df_valid)\n",
    "    X_valid =  train(valid_dicts)\n",
    "    y_train = df_train[target].values\n",
    "    y_valid = df_valid[target].values\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred = lr.predict(X_valid)\n",
    "\n",
    "    rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6537/3891565401.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer_6 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_202301\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_202302\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m display(answer_6)\n",
      "Cell \u001b[0;32mIn[39], line 9\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[0;34m(df_train, df_valid)\u001b[0m\n\u001b[1;32m      7\u001b[0m df_train \u001b[38;5;241m=\u001b[39m add_duration_column_by_minutes(df_train)\n\u001b[1;32m      8\u001b[0m train_dicts \u001b[38;5;241m=\u001b[39m drop_outliers(df_train)\n\u001b[0;32m----> 9\u001b[0m X_train \u001b[38;5;241m=\u001b[39m  \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m df_train[target]\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_dicts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(train_dicts):\n\u001b[1;32m     12\u001b[0m     dv \u001b[38;5;241m=\u001b[39m DictVectorizer()\n\u001b[0;32m---> 13\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mdv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:316\u001b[0m, in \u001b[0;36mDictVectorizer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a list of feature name -> indices mappings and transform X.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    Like fit(X) followed by transform(X), but does not require\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        Feature vectors; always 2-d.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:226\u001b[0m, in \u001b[0;36mDictVectorizer._transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# collect all the possible feature names and build sparse matrix at\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# same time\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    228\u001b[0m             feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator, v)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "answer_6 = train_and_predict(df_202301,df_202302)\n",
    "display(answer_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
